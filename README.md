# Proyecto Final de MLOps - Pipeline de Predicci√≥n de Enfermedades Card√≠acas
### Aprendizaje de M√°quina I - CEIA - FIUBA

Este repositorio contiene un pipeline completo de MLOps para la clasificaci√≥n de enfermedades card√≠acas, utilizando Docker, Apache Airflow, MLflow y FastAPI.


## Equipo

  * Sebastian Biagiola
  * Erlin Rey
  * Santiago Casado
  * Daniel Baz√°n
  * Jonathan Matias Borda

-----

### Tabla de Contenidos
1.  [Caracter√≠sticas](#caracter√≠sticas)
2.  [Arquitectura del Sistema](#arquitectura-del-sistema)
3.  [Estructura del Proyecto](#estructura-del-proyecto)
4.  [Modelo de Predicci√≥n](#modelo-de-predicci√≥n)
5.  [Requisitos Previos](#requisitos-previos)
6.  [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
7.  [Uso del Sistema](#uso-del-sistema)
8.  [Referencia de la API](#referencia-de-la-api)
9.  [Personalizaci√≥n](#personalizaci√≥n)
10.  [Comandos √ötiles](#comandos-√∫tiles)
11. [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)
12. [Contribuciones](#contribuciones)
13. [Licencia](#licencia)
14. [Equipo](#equipo)

---

## Caracter√≠sticas

* **Pipeline Automatizado**: Orquestaci√≥n de la extracci√≥n, preprocesamiento, entrenamiento y evaluaci√≥n de modelos.
* **Comparaci√≥n de Modelos**: Entrenamiento y evaluaci√≥n en paralelo de Random Forest, Logistic Regression y SVM.
* **Seguimiento de Experimentos**: Gesti√≥n completa del ciclo de vida de los modelos con MLflow.
* **API REST para Inferencia**: Servicio de predicciones en tiempo real con FastAPI.
* **Orquestaci√≥n de Workflows**: Flujos de trabajo gestionados con Apache Airflow.
* **Almacenamiento de Objetos**: MinIO como backend compatible con S3 para artefactos y datasets.
* **Entorno Containerizado**: Todo el stack de servicios se ejecuta en contenedores Docker.

---

## Arquitectura del Sistema

```

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Airflow UI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   (Port 8080)   ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MLflow UI     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   PostgreSQL    ‚îÇ
‚îÇ   (Port 5432)   ‚îÇ      ‚îÇ      ‚îÇ (DB Backend)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   MinIO (S3)    ‚îÇ
‚îÇ   (Port 8800)   ‚îÇ      ‚îÇ      ‚îÇ (Port 9000)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Docker  ‚îÇ
‚îÇ Network ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Almacenamiento S3 (MinIO)

Buckets autom√°ticamente creados:
- `data`: Para datasets y datos procesados
- `mlflow`: Para artefactos de MLflow


```

#### Componentes Principales
| Componente | Descripci√≥n | Puerto |
| :--- | :--- | :--- |
| **Apache Airflow** | Orquestaci√≥n de workflows y pipelines de ML | `8080` |
| **MLflow** | Gesti√≥n de experimentos, modelos y artefactos | `5000` |
| **FastAPI** | API REST para servir los modelos entrenados | `8800` |
| **MinIO** | Almacenamiento de objetos (S3-compatible) | `9000` (API), `9001` (UI) |
| **PostgreSQL**| Base de datos para los metadatos de Airflow y MLflow | `5432` |
| **Valkey** | Base de datos key-value para el broker de Celery en Airflow | `6379` |

---

## Estructura del Proyecto

```

MLOps/
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îú‚îÄ‚îÄ dags/                 \# Contiene los DAGs de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ logs/                 \# Almacena los logs generados por Airflow
‚îÇ   ‚îú‚îÄ‚îÄ plugins/              \# Para plugins personalizados de Airflow
‚îÇ   ‚îî‚îÄ‚îÄ config/               \# Archivos de configuraci√≥n de Airflow
‚îú‚îÄ‚îÄ data/                     \# Datasets para el proyecto
‚îÇ   ‚îî‚îÄ‚îÄ heart.csv             \# Dataset de enfermedades card√≠acas
‚îú‚îÄ‚îÄ models/                   \# Modelos entrenados (si se guardan localmente)
‚îú‚îÄ‚îÄ scripts/                  \# L√≥gica del modelo y scripts de utilidades
‚îÇ   ‚îú‚îÄ‚îÄ model\_utils.py        \# Clases y funciones para el modelo
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      \# Dependencias de Python para los scripts
‚îú‚îÄ‚îÄ dockerfiles/              \# Dockerfiles para construir las im√°genes
‚îÇ   ‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îî‚îÄ‚îÄ fastapi/
‚îú‚îÄ‚îÄ docker-compose.yaml       \# Define y configura todos los servicios
‚îú‚îÄ‚îÄ env.example               \# Plantilla para las variables de entorno
‚îî‚îÄ‚îÄ mlflow\_hyperparameter\_tuning.py \# Script de ejemplo para MLflow

````

---

## Modelo de Predicci√≥n

Este proyecto aborda un problema de clasificaci√≥n binaria para predecir la presencia de enfermedad card√≠aca.

- **Qu√© predice**: probabilidad/presencia de enfermedad card√≠aca (0 = no, 1 = s√≠).
- **Entrada del modelo**: 13 caracter√≠sticas cl√≠nicas num√©ricas del dataset de coraz√≥n (`data/heart.csv`). En el endpoint `/predict` se env√≠an en una lista llamada `features`, en el mismo orden usado durante el entrenamiento. Referencia habitual del conjunto UCI Heart Disease:
  - `age`, `sex`, `cp`, `trestbps`, `chol`, `fbs`, `restecg`, `thalach`, `exang`, `oldpeak`, `slope`, `ca`, `thal`.
- **Estrategia y algoritmos**: se entrenan y comparan m√∫ltiples modelos definidos en `scripts/models/`:
  - Regresi√≥n Log√≠stica (`HeartDiseaseLogisticRegressionModel`)
  - Random Forest (`HeartDiseaseRandomForestModel`)
  - SVM (`HeartDiseaseSVMModel`)
- **Selecci√≥n y tracking**: el desempe√±o se registra con MLflow; el mejor modelo se registra en el Model Registry con el nombre `heart_disease_classifier` y es el que sirve FastAPI por defecto.
- **Tuning opcional**: puedes ejecutar `mlflow_hyperparameter_tuning.py` para buscar hiperpar√°metros y registrar corridas en MLflow.

> Nota: el servicio de inferencia espera los valores ya num√©ricos y en el mismo orden que el entrenamiento. Ver ejemplo en la secci√≥n [Referencia de la API](#referencia-de-la-api).

---

## Requisitos Previos

1. **Docker**: Instala Docker Desktop o Docker Engine
2. **Docker Compose**: Viene incluido con Docker Desktop

Para verificar su instalaci√≥n, ejecute:
```bash
docker --version
docker-compose --version
````

-----

## Instalaci√≥n y Configuraci√≥n

1.  **Clonar el repositorio**

    ```bash
    git clone [https://github.com/joniborda/MLOps.git](https://github.com/joniborda/MLOps.git)
    cd MLOps
    ```

2.  **Crear el archivo de variables de entorno**

    ```bash
    cp env.example .env
    ```

    En sistemas Linux o macOS, es necesario configurar el UID del usuario actual para evitar problemas de permisos con Airflow:

    ```bash
    echo "AIRFLOW_UID=$(id -u)" >> .env
    ```

3.  **Levantar todos los servicios**

    ```bash
    docker compose --profile all up
    ```

    
4.  **Verificar el estado de los contenedores**

    ```bash
    docker ps -a
    ```

    

-----

## Uso del Sistema

#### Acceso a los Servicios

Una vez iniciados los contenedores, las interfaces est√°n disponibles en las siguientes URLs:

| Servicio | URL | Usuario | Contrase√±a |
| :--- | :--- | :--- | :--- |
| **Airflow** | `http://localhost:8080` | `airflow` | `airflow` |
| **MLflow** | `http://localhost:5000` | - | - |
| **MinIO Console** | `http://localhost:9001` | `minio` | `minio123` |
| **FastAPI** | `http://localhost:8800` | - | - |
| **API Docs** | `http://localhost:8800/docs` | - | - |

#### Pipeline con ajuste autom√°tico de hiperpar√°metros

1. Inicia sesi√≥n en Airflow y activa el DAG `mlops_pipeline`.  
2. Lanza una ejecuci√≥n manual (`Play ‚Üí Trigger DAG w/ config`).  
3. El DAG ejecuta las etapas siguientes:
   1. `extract_data`: carga el dataset (real o sint√©tico) y lo deja en MinIO.
   2. `preprocess_data`: limpia, escala y genera `train/test`, guardando los archivos en `/tmp` y en MinIO.
   3. `train_random_forest`, `train_logistic_regression`, `train_svm`: cada tarea lee los datos procesados y entrena su modelo con los par√°metros definidos en `airflow/config/model_params.yaml`.
   4. `evaluate_*`: cada modelo se eval√∫a en el set de test y deja m√©tricas/artefactos en MLflow.
   5. `select_best_model`: compara el `accuracy` de las tres evaluaciones y devuelve el mejor.
4. A continuaci√≥n corre `tune_best_model`, que reentrena el modelo ganador aplicando ¬±10‚ÄØ% a los hiperpar√°metros num√©ricos (se excluyen `random_state` y valores booleanos) y se queda con la variante de mayor `accuracy`.  
5. Las m√©tricas y par√°metros resultantes quedan disponibles en las Variables de Airflow:
   - `best_model_tuning_label`
   - `best_model_tuned_params`
   - `best_model_tuned_accuracy`
6. Si realizas cambios en el DAG, fuerza la recarga sin reiniciar todo el stack con:
   ```bash
   docker compose exec -T airflow-scheduler airflow dags reserialize -d mlops_pipeline
   ```

> üí° Recomendaci√≥n: para que el ajuste del modelo SVM no sea finalizado por falta de memoria, reserva al menos 6‚ÄØGB de RAM para Docker (el default de 4‚ÄØGB suele quedarse corto).

#### Ejecutar el Pipeline de Machine Learning

1.  Acceder a la interfaz de **Airflow**: `http://localhost:8080`.
2.  Iniciar sesi√≥n con las credenciales por defecto.
3.  Localizar el DAG llamado `mlops_pipeline`.
4.  Activar el DAG utilizando el interruptor (toggle).
5.  Ejecutarlo manualmente haciendo clic en el bot√≥n de "Play".

#### Ejecutar Experimentos de Hyperparameter Tuning

Puedes ejecutar un script de ejemplo para buscar hiperpar√°metros y registrar los resultados en MLflow.

1.  **Configurar variables de entorno en la terminal**:

    ```bash
    export MLFLOW_TRACKING_URI=http://localhost:5000
    export AWS_ACCESS_KEY_ID=minio
    export AWS_SECRET_ACCESS_KEY=minio123
    export MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
    ```

2.  **Ejecutar el script**:

    ```bash
    python mlflow_hyperparameter_tuning.py
    ```

-----

## Referencia de la API

#### Realizar una Predicci√≥n (Ejemplo con `curl`)

  * **Request (`POST /predict`)**

    ```bash
    curl -X POST "http://localhost:8800/predict" \
      -H "Content-Type: application/json" \
      -d '{
        "features": [63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]
      }'
    ```

  * **Response**

    ```json
    {
      "prediction": 1,
      "probability": 0.85,
      "model_version": "3"
    }
    ```

#### Realizar una Predicci√≥n (Ejemplo con `Python`)

```python
import requests
import json

# Datos de ejemplo (13 caracter√≠sticas)
sample_data = {
    "features": [63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]
}

# Hacer la petici√≥n a la API
response = requests.post(
    "http://localhost:8800/predict",
    json=sample_data
)

if response.status_code == 200:
    result = response.json()
    print(f"Predicci√≥n: {result['prediction']}")
    print(f"Probabilidad: {result['probability']:.2%}")
    print(f"Versi√≥n del modelo: {result['model_version']}")
else:
    print(f"Error: {response.status_code}")
    print(response.json())
```

#### Otros Endpoints Disponibles

  * `GET /`: Devuelve informaci√≥n b√°sica de la API.
  * `GET /health`: Realiza un chequeo de salud del servicio.
  * `GET /model/info`: Devuelve metadatos del modelo actualmente cargado en memoria.
  * `POST /model/reload`: Fuerza la recarga del √∫ltimo modelo registrado en MLflow.

La documentaci√≥n interactiva completa de la API est√° disponible en `http://localhost:8800/docs`.

-----

## Personalizaci√≥n

### Agregar Nuevos DAGs

1.  Crea tu archivo Python en la carpeta `airflow/dags/`.
2.  El DAG aparecer√° autom√°ticamente en la UI de Airflow despu√©s de unos momentos.

### Modificar la API

1.  Edita el archivo `dockerfiles/fastapi/app.py` con tu nueva l√≥gica.
2.  Reconstruye la imagen del contenedor de FastAPI: `docker-compose build fastapi`.
3.  Reinicia el servicio para aplicar los cambios: `docker-compose restart fastapi`.

### Configurar Conexiones de Airflow

Para agregar conexiones de forma declarativa, edita el archivo `airflow/config/connections.yaml`.

-----

## Comandos √ötiles

### Gesti√≥n de Servicios

```bash
# Levantar todos los servicios en segundo plano
docker-compose --profile all up -d

# Detener todos los servicios
docker-compose --profile all down

# Ver el estado de los contenedores
docker-compose ps

# Ver los logs de un servicio espec√≠fico en tiempo real
docker-compose logs -f [nombre-del-servicio]

# Detener y eliminar vol√∫menes (¬°CUIDADO! Borra todos los datos)
docker-compose --profile all down --volumes
```

### Debugging con Airflow CLI

```bash
# Listar todos los DAGs disponibles
docker-compose run airflow-cli dags list

# Ver la informaci√≥n detallada de un DAG
docker-compose run airflow-cli dags show mlops_pipeline

# Pausar un DAG
docker-compose run airflow-cli dags pause mlops_pipeline

# Reanudar un DAG
docker-compose run airflow-cli dags unpause mlops_pipeline
```

-----

## Soluci√≥n de Problemas

  * **Servicios no inician o fallan al levantar**:

    1.  **Verifica que Docker est√© activo** y que los contenedores se hayan creado. El comando `ps` te mostrar√° el estado de cada uno.
        ```bash
        docker-compose ps
        ```
    2.  **Revisa los logs** del servicio que est√° fallando para ver el mensaje de error espec√≠fico.
        ```bash
        docker-compose logs [nombre-del-servicio]
        ```
    3.  **Confirma que los puertos** definidos en el archivo `.env` (ej. `8080`, `5000`, etc.) no est√©n siendo utilizados por otro programa en tu sistema.

  * **Errores de permisos en Linux/macOS**:

      * Aseg√∫rate de que la variable `AIRFLOW_UID` en el archivo `.env` coincida con tu ID de usuario (`id -u`). Adicionalmente, puedes reasignar permisos a la carpeta de Airflow:
        ```bash
        sudo chown -R $(id -u):$(id -g) airflow/
        ```

  * **MLflow no se conecta a MinIO**:

    1.  Verifica que el contenedor de `minio` est√© en estado `running` con `docker-compose ps`.
    2.  Revisa que las variables de entorno de S3 en tu archivo `.env` sean correctas.
    3.  Verifica la conectividad de red con el contenedor: `curl http://localhost:9000`.

  * **DAGs no aparecen en la UI de Airflow**:

    1.  **Verifica si hay errores de sintaxis** en los logs del contenedor `airflow-scheduler`.
    2.  **Aseg√∫rate de que el archivo del DAG** est√© dentro de la carpeta `airflow/dags/`.
    3.  **Lista los DAGs desde el CLI** para confirmar si Airflow los ha detectado:
        ```bash
        docker-compose run airflow-cli dags list
        ```
    4.  **Para eliminar los DAGs de ejemplo** que vienen con Airflow, puedes usar el CLI:
        ```bash
        docker-compose run airflow-cli dags delete [dag_id_ejemplo]
        ```

-----

## Contribuciones

Las contribuciones a este proyecto son bienvenidas.

1.  Realiza un Fork del repositorio.
2.  Crea una nueva rama para tu funcionalidad (`git checkout -b feature/nueva-funcionalidad`).
3.  Realiza un Commit con sus cambios (`git commit -m 'Agrega nueva funcionalidad'`).
4.  Haz un Push a la rama (`git push origin feature/nueva-funcionalidad`).
5.  Abre un Pull Request.

#### Ideas para mejorar:

  - Agregar m√°s tipos de modelos al pipeline.
  - Implementar monitoreo de servicios con Grafana y Prometheus.
  - Agregar tests automatizados para la API y los componentes del pipeline.
  - Implementar un flujo de CI/CD con GitHub Actions.
  - Agregar m√°s visualizaciones y reportes en MLflow.

-----

## Licencia

Este proyecto se distribuye bajo la Licencia Apache 2.0. Consulte el archivo `LICENSE` para m√°s detalles.
